{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.6 64-bit"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "name": "Copy of LS_DS_413_Document_Classification_Assignment_Guide.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 4, Sprint 1, Module 3*\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "RIaw2IDPGfBo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Document Classification (Assignment)\n",
        "\n",
        "This notebook is for you to practice skills during lecture.\n",
        "\n",
        "Today's guided module project and assignment will be different. You already know how to do classification. You ready know how to extract features from documents. So? That means you're ready to combine and practice those skills in a [kaggle competition](https://www.kaggle.com/c/whiskey-201911/) We we will open with a five minute sprint explaining the competition, and then give you 25 minutes to work. After those twenty five minutes are up, I will give a 5-minute demo an NLP technique that will help you with document classification (*and **maybe** the competition*).\n",
        "\n",
        "Today's all about having fun and practicing your skills.\n",
        "\n",
        "## Sections\n",
        "* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n",
        "* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n",
        "* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy\n",
        "* <a href=\"#p4\">Part 4</a>: Post Lecture Assignment"
      ],
      "metadata": {
        "id": "X-0cqJc8GfBq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Feature Extraction & Classification Pipelines (Learn)\n",
        "<a id=\"p1\"></a>"
      ],
      "metadata": {
        "id": "I7YZNjEbGfBr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to run increasingly sophisticated classification models on our whisky reviews in parts 1, 2, and 3. For each of parts 1, 2, and 3, submit your best model's results to the Kaggle competition to measure `generalization accuracy` -- i.e. how well the model performs on new data."
      ],
      "metadata": {
        "id": "tfAUasgKoKVc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Classifier based on TfIdf vectorization of reviews"
      ],
      "metadata": {
        "id": "-v3SlXgD5Tk9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Follow Along \n",
        "\n",
        "What you should be doing now:\n",
        "1. Join the Kaggle Competition\n",
        "2. Download the data\n",
        "3. Train a model (try using the pipe method I just demoed)"
      ],
      "metadata": {
        "toc-hr-collapsed": true,
        "id": "DpfX8zyJGfBs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.0 Setup"
      ],
      "metadata": {
        "id": "iUrJ2rARmfkE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.0.1 Get spacy and restart runtime"
      ],
      "metadata": {
        "id": "PWCleLr4lyP7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "#YOUR CODE HERE\n",
        "# !python3 -m spacy download en_core_web_md"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-md==3.1.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.1.0/en_core_web_md-3.1.0-py3-none-any.whl (45.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 45.4 MB 10.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from en-core-web-md==3.1.0) (3.1.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (0.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.0.8)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.19.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (4.62.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.0.5)\n",
            "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.0.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (0.8.2)\n",
            "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (58.0.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.8.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.0.5)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (0.6.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.25.1)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (0.3.2)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.8 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (8.0.10)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.0.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (21.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.4.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (5.2.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.26.2)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from typer<0.4.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.0.1)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ],
      "metadata": {
        "id": "ysPkqrmcl2I8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.0.2 import necessary packages, load spacy"
      ],
      "metadata": {
        "id": "RNImGQB1l56U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import spacy"
      ],
      "outputs": [],
      "metadata": {
        "id": "l4KcM3TcMO-N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load `spacy`"
      ],
      "metadata": {
        "id": "KsNq7a5WP_Tw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "source": [
        "#YOUR CODE HERE\n",
        "nlp = spacy.load('en_core_web_lg')"
      ],
      "outputs": [],
      "metadata": {
        "id": "e1V3ApAvMDYx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.0.3 Load Kaggle Whisky Competition Data"
      ],
      "metadata": {
        "id": "UimXwG9tGfBs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "source": [
        "# !!!!! You may need to change the path !!!!!\n",
        "# You can download these datasets from the Kaggle in-class \n",
        "# competition for your cohort. \n",
        " \n",
        "train = pd.read_csv('whiskey/train.csv', index_col='id')\n",
        "test = pd.read_csv('whiskey/test.csv')"
      ],
      "outputs": [],
      "metadata": {
        "id": "Nf-b1D-wGfBt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "source": [
        "test"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>955</td>\n",
              "      <td>Think carnival aromas—the good ones, anyway—me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3532</td>\n",
              "      <td>A blend of three bourbons, between 6 and 12 ye...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1390</td>\n",
              "      <td>The nose is focused on cereal, hints of fresh ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1024</td>\n",
              "      <td>Swiss-based Chapter 7 released this 19 year ol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1902</td>\n",
              "      <td>Valkyrie replaces the current Dark Origins exp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>283</th>\n",
              "      <td>1834</td>\n",
              "      <td>Aged in a sherry cask, and the sherry is clean...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284</th>\n",
              "      <td>2848</td>\n",
              "      <td>There have been some legendary Hart Brothers b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285</th>\n",
              "      <td>3874</td>\n",
              "      <td>Aromas hint at a bitterly astringent, almost b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286</th>\n",
              "      <td>2377</td>\n",
              "      <td>Think corn: roasted, canned, creamed, mashed, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>287</th>\n",
              "      <td>2243</td>\n",
              "      <td>Amber gold color. Medium bodied and slightly o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>288 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       id                                        description\n",
              "0     955  Think carnival aromas—the good ones, anyway—me...\n",
              "1    3532  A blend of three bourbons, between 6 and 12 ye...\n",
              "2    1390  The nose is focused on cereal, hints of fresh ...\n",
              "3    1024  Swiss-based Chapter 7 released this 19 year ol...\n",
              "4    1902  Valkyrie replaces the current Dark Origins exp...\n",
              "..    ...                                                ...\n",
              "283  1834  Aged in a sherry cask, and the sherry is clean...\n",
              "284  2848  There have been some legendary Hart Brothers b...\n",
              "285  3874  Aromas hint at a bitterly astringent, almost b...\n",
              "286  2377  Think corn: roasted, canned, creamed, mashed, ...\n",
              "287  2243  Amber gold color. Medium bodied and slightly o...\n",
              "\n",
              "[288 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "LnMkWvxdGfBu",
        "outputId": "33933d8e-efab-4908-b570-7a92c7f0964b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Clean Text"
      ],
      "metadata": {
        "id": "9uPjYRcHMa7N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "source": [
        "def clean_doc(text):\n",
        "  # COMPLETE THE CODE IN THIS CELL\n",
        "  # remove new line characters\n",
        "  text = text.replace('\\\\n', ' ')\n",
        "  # remove numbers for the text\n",
        "  text = re.sub('[^a-z A-Z]', '', text)\n",
        "  # remove multiple white spaces\n",
        "  text = re.sub('[ ]{2,}', ' ', text)\n",
        "\n",
        "  # case normalize and strip extra white spaces on the far left and right hand side\n",
        "  text = text.lower().strip()\n",
        "  return text\n",
        "\n",
        "train['description'] = train['description'].apply(clean_doc)\n",
        "test['description'] = test['description'].apply(clean_doc)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "1YTBavgJMj3Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "source": [
        "train['description']"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id\n",
              "1       a marriage of and year old bourbons a mature y...\n",
              "2       there have been some legendary bowmores from t...\n",
              "3       this bottling celebrates master distiller park...\n",
              "4       what impresses me most is how this whisky evol...\n",
              "9       a caramelladen fruit bouquet followed by unend...\n",
              "                              ...                        \n",
              "4146    earthy fleshy notes with brooding grape notes ...\n",
              "4153    with its overt floral perfume notes and the sc...\n",
              "4154    an unaged whiskey from carroll county iowa wit...\n",
              "4155    fiery peat kiln smoke tar and ripe barley on t...\n",
              "4157    although its not on the label cavalry uses the...\n",
              "Name: description, Length: 2586, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "LU3Dvu_7MmSQ",
        "outputId": "5e53a3ae-00fd-4130-903d-7f472bb04d24"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Split training data into Feature Matrix and Target Vector"
      ],
      "metadata": {
        "id": "zdqYMpmFMvto"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "source": [
        "target = 'category'\n",
        "# COMPLETE THE CODE IN THIS CELL\n",
        "y = train[target]\n",
        "X = train['description']"
      ],
      "outputs": [],
      "metadata": {
        "id": "DJFIJlu3MzH7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "source": [
        "print(X)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            description\n",
            "id                                                     \n",
            "1     a marriage of and year old bourbons a mature y...\n",
            "2     there have been some legendary bowmores from t...\n",
            "3     this bottling celebrates master distiller park...\n",
            "4     what impresses me most is how this whisky evol...\n",
            "9     a caramelladen fruit bouquet followed by unend...\n",
            "...                                                 ...\n",
            "4146  earthy fleshy notes with brooding grape notes ...\n",
            "4153  with its overt floral perfume notes and the sc...\n",
            "4154  an unaged whiskey from carroll county iowa wit...\n",
            "4155  fiery peat kiln smoke tar and ripe barley on t...\n",
            "4157  although its not on the label cavalry uses the...\n",
            "\n",
            "[2586 rows x 1 columns]\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Define Pipeline Components\n",
        "We can try`RandomForestClassifier()`,  `GradientBoostingClassifier()` from the `sklearn` library, and `XGBClassifier()` from the `xgboost` library."
      ],
      "metadata": {
        "id": "5IHzPRZ2GfBv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "source": [
        "# limiting max_features to 500 to speed up training on Colab.\n",
        "# COMPLETE THE CODE IN THIS CELL\n",
        "vect = TfidfVectorizer(stop_words='english', tokenizer=None)\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "pipe = Pipeline([('vect', vect), ('clf', clf)])"
      ],
      "outputs": [],
      "metadata": {
        "id": "Ju6TgtdzGfBw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4 Define Your Search Space\n",
        "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
      ],
      "metadata": {
        "id": "clooAQkiGfBx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "source": [
        "print(len(X))\n",
        "print(len(y))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2586\n",
            "2586\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "source": [
        "# COMPLETE THE CODE IN THIS CELL\n",
        "# Parameters to search in dictionary \n",
        "parameters = {\n",
        "    'vect__max_df': [.75], #[x/100 for x in range(75, 101, 25)],\n",
        "    'vect__min_df': [10], #[x for x in range(6, 11, 2)],\n",
        "    'vect__max_features': [600], #[x for x in range(500, 1001, 100)],\n",
        "    # 'vect__ngram_range': [(1, x+1) for x in range(3)],\n",
        "    'clf__n_estimators': [100], #[x for x in range(20, 101, 20)],\n",
        "    'clf__max_depth': [25] #[x for x in range(5, 26, 5)]\n",
        "}\n",
        "\n",
        "# Implement a grid search with cross-validation\n",
        "grid_search = GridSearchCV(pipe, parameters, n_jobs=-2, cv=3, verbose=1)\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# Display the best score from the grid search\n",
        "print(grid_search.best_score_)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done   3 out of   3 | elapsed:    2.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8708430007733953\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3R9iNggGfBx",
        "outputId": "d5136d65-9bc5-488f-99bf-fe8de19bc22f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "source": [
        "# Display the best parameters from the grid search\n",
        "print(grid_search.best_params_)\n",
        "print(grid_search.best_score_)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'clf__max_depth': 25, 'clf__n_estimators': 100, 'vect__max_df': 0.75, 'vect__max_features': 600, 'vect__min_df': 10}\n",
            "0.8708430007733953\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGd5eDV6PC3X",
        "outputId": "13c20cf0-54e3-4125-9715-b406117e3781"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.5 Make a Submission File\n",
        "*Note:* In a typical Kaggle competition, you are only allowed two submissions a day, so only submit when your predicted test accuracy is the highest you can make it. For this competition the max daily submissions are capped at **20**.  The submission file is made from the results of running your best model on the test data set, for which we don't get the targets."
      ],
      "metadata": {
        "id": "lK4r904hGfBy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "source": [
        "# COMPLETE THE CODE IN THIS CELL\n",
        "# Predictions on **test** sample\n",
        "pred = grid_search.predict(test['description'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "gEQo7ikVGfBy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "source": [
        "pred"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 4, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1,\n",
              "       1, 1, 4, 1, 1, 1, 3, 1, 4, 2, 1, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1,\n",
              "       1, 1, 1, 2, 1, 1, 3, 1, 3, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 4,\n",
              "       2, 1, 1, 1, 1, 3, 1, 1, 4, 1, 3, 2, 1, 1, 1, 1, 2, 1, 1, 3, 2, 1,\n",
              "       1, 3, 1, 1, 1, 1, 1, 4, 1, 1, 4, 3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2,\n",
              "       3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 2, 2, 4, 1, 1,\n",
              "       1, 1, 3, 2, 1, 1, 1, 1, 1, 3, 2, 1, 1, 3, 4, 1, 1, 1, 3, 1, 1, 1,\n",
              "       1, 1, 3, 1, 1, 1, 1, 1, 4, 1, 1, 1, 3, 1, 2, 2, 1, 3, 2, 1, 1, 1,\n",
              "       1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 4, 1, 3, 1, 4, 1, 1, 2, 3, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 4, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 3,\n",
              "       2, 2, 1, 3, 1, 3, 3, 3, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 2, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 4, 1, 1, 1, 1,\n",
              "       2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "source": [
        "# COMPLETE THE CODE IN THIS CELL\n",
        "submission = pd.DataFrame({'id': test['id'], 'category': pred})\n",
        "submission['category'] = submission['category'].astype('int64')"
      ],
      "outputs": [],
      "metadata": {
        "id": "VtE6ZpNnGfBy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "source": [
        "# Make Sure the Category is an Integer\n",
        "submission.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>955</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3532</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1390</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1024</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1902</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  category\n",
              "0   955         2\n",
              "1  3532         2\n",
              "2  1390         1\n",
              "3  1024         1\n",
              "4  1902         1"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "MrkTTtjoGfBz",
        "outputId": "7d0d5c2f-495c-4d65-f02b-9b8ffd00ec89"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "source": [
        "submission_number = 0"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "source": [
        "# Save your Submission File\n",
        "# Best to Use an Integer or Timestamp for different versions of your model\n",
        "# submission_number = 0\n",
        "\n",
        "submission.to_csv(f'submission{submission_number}.csv', index=False)\n",
        "submission_number += 1"
      ],
      "outputs": [],
      "metadata": {
        "id": "hUACBAiMGfB0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenge\n",
        "\n",
        "You're trying to achieve a minimum of 75% Accuracy on your model."
      ],
      "metadata": {
        "id": "hpg3M7vDGfB0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Add Latent Semantic Indexing to pipeline (Learn)\n",
        "<a id=\"p2\"></a>"
      ],
      "metadata": {
        "id": "7rwWt0TNGfB0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Follow Along\n",
        "1. Join the Kaggle Competition\n",
        "2. Download the data\n",
        "3. Train a model & try: \n",
        "    - Creating a Text Extraction & Classification Pipeline\n",
        "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
        "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
        "4. Make a submission to Kaggle \n"
      ],
      "metadata": {
        "toc-hr-collapsed": true,
        "id": "PZXSsX8rGfB0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Define Pipeline Components\n",
        "\n",
        "Nest pipelines to perform SVD on our vectorization (LSA)"
      ],
      "metadata": {
        "id": "75X-i44lGfB0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "source": [
        "# COMPLETE THE CODE IN THIS CELL\n",
        "# Transforming our Vectorization with SVD is how LSA generates topic columns\n",
        "svd = TruncatedSVD(\n",
        "    algorithm='randomized',\n",
        "    n_iter=10\n",
        ")\n",
        "\n",
        "# vectorizer and classifier like before\n",
        "vect = TfidfVectorizer(\n",
        "    stop_words='english', tokenizer=None\n",
        ")\n",
        "clf = XGBClassifier()\n",
        "\n",
        "# LSA pipeline with vectorizer & truncated SVD\n",
        "lsa = Pipeline([\n",
        "    ('vect', vect),\n",
        "    ('svd', svd)\n",
        "])\n",
        "\n",
        "# combine LSA pipeline together with classifier\n",
        "pipe = Pipeline([('lsa', lsa), ('clf', clf)])"
      ],
      "outputs": [],
      "metadata": {
        "id": "QG_lFmOyGfB1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Define Your grid search space and run a grid search with cross-validation\n",
        "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
      ],
      "metadata": {
        "id": "uF7_arccGfB1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "source": [
        "# COMPLETE THE CODE IN THIS CELL\n",
        "parameters = {\n",
        "    'lsa__svd__n_components': [x for x in range(2, 7, 2)], # 6\n",
        "    'lsa__vect__max_df': [x/100 for x in range(50, 101, 25)], # .75\n",
        "    'clf__max_depth': [x for x in range(5, 26, 5)] # 5\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipe,parameters, cv=3, n_jobs=-1, verbose=1)\n",
        "grid_search.fit(X, y)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 45 candidates, totalling 135 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
            "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[17:07:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:07:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:07:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:07:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:07:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:07:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:07:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:07:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:07:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:07:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:07:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:07:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:07:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:07:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:07:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:07:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   35.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[17:08:27] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:27] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:27] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:32] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:32] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:08:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:25] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:27] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:27] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:32] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:09:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[17:10:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 135 out of 135 | elapsed:  3.2min finished\n",
            "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[17:11:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3,\n",
              "             estimator=Pipeline(steps=[('lsa',\n",
              "                                        Pipeline(steps=[('vect',\n",
              "                                                         TfidfVectorizer(stop_words='english')),\n",
              "                                                        ('svd',\n",
              "                                                         TruncatedSVD(n_iter=10))])),\n",
              "                                       ('clf',\n",
              "                                        XGBClassifier(base_score=None,\n",
              "                                                      booster=None,\n",
              "                                                      colsample_bylevel=None,\n",
              "                                                      colsample_bynode=None,\n",
              "                                                      colsample_bytree=None,\n",
              "                                                      gamma=None, gpu_id=None,\n",
              "                                                      importance_type='gain',\n",
              "                                                      interaction_constraints=None,\n",
              "                                                      learning_...\n",
              "                                                      monotone_constraints=None,\n",
              "                                                      n_estimators=100,\n",
              "                                                      n_jobs=None,\n",
              "                                                      num_parallel_tree=None,\n",
              "                                                      random_state=None,\n",
              "                                                      reg_alpha=None,\n",
              "                                                      reg_lambda=None,\n",
              "                                                      scale_pos_weight=None,\n",
              "                                                      subsample=None,\n",
              "                                                      tree_method=None,\n",
              "                                                      validate_parameters=None,\n",
              "                                                      verbosity=None))]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'clf__max_depth': [5, 10, 15, 20, 25],\n",
              "                         'lsa__svd__n_components': [2, 4, 6],\n",
              "                         'lsa__vect__max_df': [0.5, 0.75, 1.0]},\n",
              "             verbose=1)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANy4UkVeGfB1",
        "outputId": "8acdd38d-2d77-49b7-e31c-e605aafac48a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "source": [
        "grid_search.best_score_"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8464810518174787"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAXQ0qZfRNWu",
        "outputId": "7d9e537b-7e65-4e70-f141-ff4ee501c374"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "source": [
        "grid_search.best_params_"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clf__max_depth': 5, 'lsa__svd__n_components': 6, 'lsa__vect__max_df': 0.75}"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oVwOkS9RPLY",
        "outputId": "5d0836ff-d150-4422-c434-69514295720e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Make a Submission File"
      ],
      "metadata": {
        "id": "0xZotkIEGfB2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "source": [
        "# Predictions on test sample\n",
        "pred = grid_search.predict(test['description'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "25fSUB-7GfB2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "source": [
        "submission = pd.DataFrame({'id': test['id'], 'category':pred})\n",
        "submission['category'] = submission['category'].astype('int64')"
      ],
      "outputs": [],
      "metadata": {
        "id": "uAawXel0GfB2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "source": [
        "# Make Sure the Category is an Integer\n",
        "submission.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>955</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3532</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1390</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1024</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1902</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  category\n",
              "0   955         2\n",
              "1  3532         2\n",
              "2  1390         1\n",
              "3  1024         1\n",
              "4  1902         1"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "1VxekvAdGfB2",
        "outputId": "87e6b868-e27c-4a40-b940-eb4b9392e94e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "source": [
        "# Save your Submission File\n",
        "# Best to Use an Integer or Timestamp for different versions of your model\n",
        "\n",
        "submission.to_csv(f'submission{submission_number}.csv', index=False)\n",
        "submission_number +=1"
      ],
      "outputs": [],
      "metadata": {
        "id": "mirtMVSWGfB2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenge\n",
        "\n",
        "Continue to apply Latent Semantic Indexing (LSI) to various datasets. "
      ],
      "metadata": {
        "id": "FLtOAlokGfB3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Add Spacy Word Embeddings\n",
        "<a id=\"p3\"></a>"
      ],
      "metadata": {
        "id": "l_6YzbjHGfB3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Process the data set with spacy"
      ],
      "metadata": {
        "id": "voankIL7GfB3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "source": [
        "# Apply to your Dataset\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "from scipy.stats import randint\n",
        "\n",
        "param_dist = {\n",
        "    \n",
        "    'max_depth' : randint(3,10),\n",
        "    'min_samples_leaf': randint(2,15)\n",
        "}"
      ],
      "outputs": [],
      "metadata": {
        "id": "sTE0VTyMGfB3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "source": [
        "# Continue Word Embedding Work Here\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "def get_word_vectors(docs):\n",
        "    # YOUR CODE HERE\n",
        "    return [nlp(doc).vector for doc in docs]\n",
        "\n",
        "X_train_emb = get_word_vectors(train['description'])\n",
        "X_test_emb = get_word_vectors(test['description'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "rxESV0tdGfB4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "source": [
        "rfc = RandomForestClassifier(oob_score=True)\n",
        "\n",
        "rfc.fit(X_train_emb, y)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(oob_score=True)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Duovxl3NUQWk",
        "outputId": "4ab14f9d-80c0-4cfe-e02a-073a38c261e3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "source": [
        "# massively overfit with the Random Forest\n",
        "print('Training Accuracy: ', rfc.score(X_train_emb, y))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:  1.0\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sErmIzPmUcb4",
        "outputId": "7fe144f0-cf53-409e-bbe3-33238be36f32"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we use oob_score_ (out-of-bag score) as a **proxy** for the test score;<br>\n",
        "for your submission, you will predict on the test set, as before"
      ],
      "metadata": {
        "id": "E6gj2dtAsojE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "source": [
        "# validation looks decent without any tuning\n",
        "\n",
        "rfc.oob_score_"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7494199535962877"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emXFzc-EUkIo",
        "outputId": "3a916c27-bdaa-4358-dbfb-1e03bddfd54c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Make a Submission File"
      ],
      "metadata": {
        "id": "HNUdL4rtGfB4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "source": [
        "# YOUR CODE HERE\n",
        "pred = rfc.predict(X_test_emb)"
      ],
      "outputs": [],
      "metadata": {
        "id": "--t3j2Hn_reu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "source": [
        "submission = pd.DataFrame({'id': test['id'], 'category': pred})\n",
        "submission['category'] = submission['category'].astype('int64')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "source": [
        "submission.to_csv(f'submission{submission_number}.csv', index=False)\n",
        "submission_number +=1"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenge\n",
        "\n",
        "What you should be doing now:\n",
        "1. Join the Kaggle Competition\n",
        "2. Download the data\n",
        "3. Train a model & try: \n",
        "    - Creating a Text Extraction & Classification Pipeline\n",
        "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
        "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
        "    - Try to extract word embeddings with Spacy and use those embeddings as your features for a classification model.\n",
        "4. Make a submission to Kaggle "
      ],
      "metadata": {
        "id": "OuAIyBRPGfB4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Post Lecture Assignment\n",
        "<a id=\"p4\"></a>\n",
        "\n",
        "Your primary assignment this afternoon is to achieve a minimum of 75% accuracy on the Kaggle competition. <br>\n",
        "Once you have achieved that goal, please explore a few of the following topics: \n",
        "\n",
        "1. Research \"Sentiment Analysis\". Provide answers in markdown to the following questions: \n",
        "    - What is \"Sentiment Analysis\"? \n",
        "    - Is Document Classification different than \"Sentiment Analysis\"? Provide evidence for your response\n",
        "    - How do you create labeled sentiment data? Are those labels really sentiment?\n",
        "    - What are common applications of sentiment analysis?\n",
        "2. Research why word embeddings worked better for the lecture notebook than on the whiskey competition.\n",
        "    - This [text classification documentation](https://developers.google.com/machine-learning/guides/text-classification/step-2-5) from Google might be of interest\n",
        "    - Neural Networks are becoming more popular for document classification. Why is that the case?\n",
        "\n",
        "3. Research Singular Value Decomposition (SVD), one of the most important and powerful methods in Applied Mathematics and in all of Machine Learning.  Principal Components Analysis (PCA) -- which we used in Module 2 -- is closely releated to SVD.<br>\n",
        "\n",
        "* [Daniela Witten](https://www.danielawitten.com/), a Professor of Mathematical Statistics at the University of Washington, recently penned a highly amusing and informative [tweetstorm](https://twitter.com/WomenInStat/status/1285611042446413824) about SVD, well worth reading!<br>\n",
        "* [Stanford University Lecture on SVD](https://www.youtube.com/watch?v=P5mlg91as1c) <br>\n",
        "* [StatQuest Principal Components Analysis](https://www.youtube.com/watch?v=FgakZw6K1QQ)<br>\n",
        "* [Luis Serrano Principal Components Analysis](https://www.youtube.com/watch?v=g-Hb26agBFg)<br>\n",
        "\n"
      ],
      "metadata": {
        "id": "1gM_zN5zGfB5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis\n",
        "Sentiment analysis is the use of natural language processing to systematically define subjective information.\n",
        "\n",
        "# Documentation Classification vs Sentimental Analysis\n",
        "Yes, they are different, Documentation Classification by definition classifying documents, however this does not necessarily mean algorithmically. You can classify documents manually. Sentimental Analysis is Documentation Classification except using an algorithm to do it.\n",
        "\n",
        "# Common Applications of Sentiment Analysis\n",
        "* Monitoring Social Media\n",
        "* Automatic Customer Support\n",
        "* Market Research"
      ],
      "metadata": {}
    }
  ]
}